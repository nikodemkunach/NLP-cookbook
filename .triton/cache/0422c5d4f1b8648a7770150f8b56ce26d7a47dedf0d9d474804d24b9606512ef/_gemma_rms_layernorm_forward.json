{"hash": "0422c5d4f1b8648a7770150f8b56ce26d7a47dedf0d9d474804d24b9606512ef", "target": {"backend": "cuda", "arch": 89, "warp_size": 32}, "num_warps": 8, "num_ctas": 1, "num_stages": 3, "maxnreg": null, "cluster_dims": [1, 1, 1], "ptx_version": null, "enable_fp_fusion": true, "allow_fp8e4nv": true, "allow_fp8e4b15": true, "default_dot_input_precision": "tf32", "allowed_dot_input_precisions": ["tf32", "tf32x3", "ieee"], "max_num_imprecise_acc_default": 0, "extern_libs": [["libdevice", "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"]], "debug": null, "backend_name": "cuda", "shared": 32, "name": "_gemma_rms_layernorm_forward"}